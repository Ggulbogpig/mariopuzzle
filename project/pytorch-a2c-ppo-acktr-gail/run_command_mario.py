python main.py --env-name "mario_gan-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/exp1_1/" --log-dir "./logs/exp1_1/" --num-env-steps 1000000
python main.py --env-name "mario_gan-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/exp1_2/" --log-dir "./logs/exp1_2/" --num-env-steps 1000000 --cuda-id 2 
python main.py --env-name "mario_gan-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/exp1_3/" --log-dir "./logs/exp1_3/" --num-env-steps 1000000

python main.py --env-name "mario_gan-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/exp2_1/" --log-dir "./logs/exp2_1/" --num-env-steps 1000000
python main.py --env-name "mario_gan-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/exp2_2/" --log-dir "./logs/exp2_2/" --num-env-steps 1000000 --cuda-id 0
python main.py --env-name "mario_gan-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/exp2_3/" --log-dir "./logs/exp2_3/" --num-env-steps 1000000 --cuda-id 1

python main.py --env-name "mario_gan-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/exp3_1/" --log-dir "./logs/exp3_1/" --num-env-steps 1000000 --cuda-id 0
python main.py --env-name "mario_gan-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/exp3_2/" --log-dir "./logs/exp3_2/" --num-env-steps 1000000 --cuda-id 1
python main.py --env-name "mario_gan-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/exp3_3/" --log-dir "./logs/exp3_3/" --num-env-steps 1000000 --cuda-id 2

python main.py --env-name "mario_gan-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01--save-dir "./trained_models/exp3_3_a/" --log-dir "./logs/exp3_3_a/" --num-env-steps 1000000 --cuda-id 2


python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment1/" --log-dir "./logs/experiment1/" --num-env-steps 1000000 --experiment 1 --cuda-id 0
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment2/" --log-dir "./logs/experiment2/" --num-env-steps 1000000 --experiment 2 --cuda-id 1 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment3/" --log-dir "./logs/experiment3/" --num-env-steps 1000000 --experiment 3 --cuda-id 2 &

nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment3/" --log-dir "./logs/experiment3/" --num-env-steps 1000000 --experiment 3 --cuda-id 0 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment4/" --log-dir "./logs/experiment4/" --num-env-steps 1000000 --experiment 4 --cuda-id 1 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment5/" --log-dir "./logs/experiment5/" --num-env-steps 1000000 --experiment 5 --cuda-id 2 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment6/" --log-dir "./logs/experiment6/" --num-env-steps 1000000 --experiment 6 --cuda-id 3 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment9/" --log-dir "./logs/experiment9/" --num-env-steps 1000000 --experiment 9 --cuda-id 0 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment10/" --log-dir "./logs/experiment10/" --num-env-steps 1000000 --experiment 10 --cuda-id 1 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment11/" --log-dir "./logs/experiment11/" --num-env-steps 1000000 --experiment 11 --cuda-id 2 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment12/" --log-dir "./logs/experiment12/" --num-env-steps 1000000 --experiment 12 --cuda-id 2 &

nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment13/" --log-dir "./logs/experiment13/" --num-env-steps 1000000 --experiment 13 --cuda-id 2 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment14/" --log-dir "./logs/experiment14/" --num-env-steps 1000000 --experiment 14 --cuda-id 1 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment15/" --log-dir "./logs/experiment15/" --num-env-steps 1000000 --experiment 15 --cuda-id 3 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment16/" --log-dir "./logs/experiment16/" --num-env-steps 1000000 --experiment 16 --cuda-id 0 &

nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment17/" --log-dir "./logs/experiment17/" --num-env-steps 1000000 --experiment 17 --cuda-id 2 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment18/" --log-dir "./logs/experiment18/" --num-env-steps 1000000 --experiment 18 --cuda-id 1 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment19/" --log-dir "./logs/experiment19/" --num-env-steps 1000000 --experiment 19 --cuda-id 3 &

nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment20/" --log-dir "./logs/experiment20/" --num-env-steps 1000000 --experiment 20 --cuda-id 3 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment21/" --log-dir "./logs/experiment21/" --num-env-steps 1000000 --experiment 21 --cuda-id 1 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment22/" --log-dir "./logs/experiment22/" --num-env-steps 1000000 --experiment 22 --cuda-id 2 &

nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01 --save-dir "./trained_models/experiment23_nornn/" --log-dir "./logs/experiment23_nornn/" --num-env-steps 5000000 --experiment 23 --cuda-id 1 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment23_0.1ep/" --recurrent-policy --log-dir "./logs/experiment23_0.1ep/" --num-env-steps 5000000 --experiment 23 --cuda-id 3 &

nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 32 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment26/" --recurrent-policy --log-dir "./logs/experiment26/" --num-env-steps 1000000 --experiment 26 --cuda-id 3 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 8 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment25/" --recurrent-policy --log-dir "./logs/experiment25/" --num-env-steps 1000000 --experiment 25 --cuda-id 2 &
python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 32 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment24/" --recurrent-policy --log-dir "./logs/experiment24/" --num-env-steps 1000000 --experiment 24 --cuda-id 1
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 32 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment27/" --recurrent-policy --log-dir "./logs/experiment27/" --num-env-steps 1000000 --experiment 27 --cuda-id 1 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 32 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment28/" --recurrent-policy --log-dir "./logs/experiment28/" --num-env-steps 1000000 --experiment 28 --cuda-id 1 &

python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment7/" --recurrent-policy --log-dir "./logs/experiment7/" --num-env-steps 1000000 --experiment 7 --cuda-id 1
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment1/" --recurrent-policy --log-dir "./logs/experiment1/" --num-env-steps 1000000 --experiment 1 --cuda-id 1 &


python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment3/" --recurrent-policy --log-dir "./logs/experiment3/" --num-env-steps 1000000 --experiment 3 --cuda-id 1
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment6/" --recurrent-policy --log-dir "./logs/experiment6/" --num-env-steps 1000000 --experiment 6 --cuda-id 0 &


python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment4/" --recurrent-policy --log-dir "./logs/experiment4/" --num-env-steps 1000000 --experiment 4 --cuda-id 0
python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment2/" --recurrent-policy --log-dir "./logs/experiment2/" --num-env-steps 1000000 --experiment 2 --cuda-id 0

nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment13/" --recurrent-policy --log-dir "./logs/experiment13/" --num-env-steps 1000000 --experiment 13 --cuda-id 0 &

nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment1_no/" --recurrent-policy --log-dir "./logs/experiment1_no/" --num-env-steps 1000000 --experiment 1 --cuda-id 0 &


nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment13/" --recurrent-policy --log-dir "./logs/experiment13/" --num-env-steps 1000000 --experiment 13 --cuda-id 0 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment11/" --recurrent-policy --log-dir "./logs/experiment11/" --num-env-steps 1000000 --experiment 11 --cuda-id 0 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment12/" --recurrent-policy --log-dir "./logs/experiment12/" --num-env-steps 1000000 --experiment 12 --cuda-id 0 &

nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment14/" --recurrent-policy --log-dir "./logs/experiment14/" --num-env-steps 1000000 --experiment 14 --cuda-id 0 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment15/" --recurrent-policy --log-dir "./logs/experiment15/" --num-env-steps 1000000 --experiment 15 --cuda-id 0 &
nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment17/" --recurrent-policy --log-dir "./logs/experiment17/" --num-env-steps 1000000 --experiment 17 --cuda-id 0 &

nohup python main.py --env-name "mario_puzzle-v0" --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-processes 16 --num-steps 128 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.1 --save-dir "./trained_models/experiment18/" --recurrent-policy --log-dir "./logs/experiment18/" --num-env-steps 1000000 --experiment 18 --cuda-id 1 &

exp1_1 p=14 q=4 alpha=0.2 object=0
exp1_2 object=1
exp1_3 object=2 val=

exp2_1 p=14 q=4, alpha=0.2, object=2 val= 0.24
exp2_2 p=28, q=2 val=
exp2_3 p=1, q=56, val=

green #008000
lightgreen #90EE90

crimson  #DC143C
lightpink #FFB6C1

blue #0000FF
cornflowerblue #6495ED

exp3_1 p=14, q=2 ,object=2 val= 0.24
exp3_2 p=14, q=4 ,object=2 val= 0.24
exp3_3 p=14, q=6 ,object=2 val= 0.24